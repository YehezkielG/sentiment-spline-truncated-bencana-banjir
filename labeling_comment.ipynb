{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967952c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>createTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gibran:</td>\n",
       "      <td>1764933105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ini emg harusnya ganti rakyat sih. bgnian emg ...</td>\n",
       "      <td>1764928295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wapres aja gak pakek rompi anti peluru</td>\n",
       "      <td>1764922201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>di indo doang presiden n wapres di hujat wkwk</td>\n",
       "      <td>1764925978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>di X parah bett anjir komenannya, merinding la...</td>\n",
       "      <td>1764922173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>dy emg bnr2 idola emak2 indonesia (bahagia)\\r\\...</td>\n",
       "      <td>1764986048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>sip saya catat</td>\n",
       "      <td>1764985783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>serba salah banget, keliatan dikata pencitraan...</td>\n",
       "      <td>1764985734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>mas wapres panen pahala dari para hatter,\\r\\ns...</td>\n",
       "      <td>1764985669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>WOY TERMUL INFO LOKER DONG JADI TERMUL\\r\\nMAYA...</td>\n",
       "      <td>1764985616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  createTime\n",
       "0                                               gibran:  1764933105\n",
       "1     ini emg harusnya ganti rakyat sih. bgnian emg ...  1764928295\n",
       "2                wapres aja gak pakek rompi anti peluru  1764922201\n",
       "3         di indo doang presiden n wapres di hujat wkwk  1764925978\n",
       "4     di X parah bett anjir komenannya, merinding la...  1764922173\n",
       "...                                                 ...         ...\n",
       "4173  dy emg bnr2 idola emak2 indonesia (bahagia)\\r\\...  1764986048\n",
       "4175                                     sip saya catat  1764985783\n",
       "4176  serba salah banget, keliatan dikata pencitraan...  1764985734\n",
       "4177  mas wapres panen pahala dari para hatter,\\r\\ns...  1764985669\n",
       "4178  WOY TERMUL INFO LOKER DONG JADI TERMUL\\r\\nMAYA...  1764985616\n",
       "\n",
       "[4145 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/tiktok_comments_final.csv\")\n",
    "emoji_translator_df = pd.read_csv(\"data/emoji_translator.csv\")\n",
    "\n",
    "df = df[df['text'].str.replace(r'[^\\w\\s]', '', regex=True).str.strip() != '']\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "emoji_dict = dict(zip(emoji_translator_df[\"emoji\"], emoji_translator_df[\"aliases_all\"]))\n",
    "def translate_emojis(text):\n",
    "    for emoji, aliases in emoji_dict.items():\n",
    "        text = text.replace(emoji, f\" ({aliases})\")\n",
    "    return text\n",
    "\n",
    "df.dropna(subset=[\"text\"], inplace=True)\n",
    "df[\"text\"] = df[\"text\"].apply(translate_emojis)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c179c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = pd.read_csv(\"data/pre-trained-data.csv\")\n",
    "labeled_df = labeled_df.dropna(subset=['text', 'sentiment'])\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "labeled_data = [{\"content\": str(text), \"label\": int(label)} for text, label in zip(labeled_df[\"text\"], labeled_df[\"sentiment\"])]\n",
    "unlabeled_data = [{\"content\": str(text)} for text in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65ebe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 993/993 [00:00<00:00, 1679.93 examples/s]\n",
      "Map: 100%|██████████| 4145/4145 [00:01<00:00, 3176.90 examples/s]\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20984\\3046580120.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 : < :, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Model pretrained IndoBERT\n",
    "MODEL_NAME = \"indobenchmark/indobert-base-p1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "\n",
    "# 2. Convert ke Dataset HuggingFace\n",
    "labeled_ds = Dataset.from_list(labeled_data)\n",
    "unlabeled_ds = Dataset.from_list(unlabeled_data)\n",
    "\n",
    "# 3. Tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"content\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "labeled_ds = labeled_ds.map(tokenize, batched=True)\n",
    "unlabeled_ds = unlabeled_ds.map(tokenize, batched=True)\n",
    "\n",
    "# 4. Fine-tuning awal\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./train-checkpoint\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=labeled_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=\"./train-checkpoint/checkpoint-189\")\n",
    "trainer.save_model(\"./indobert-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc527aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(unlabeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d2d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "probs = F.softmax(torch.tensor(preds.predictions), dim=1) \n",
    "weights = torch.tensor([-1.0, 0.0, 1.0]) \n",
    "sentiment_scores = torch.matmul(probs, weights)\n",
    "\n",
    "# labeling\n",
    "pred_indices = torch.argmax(probs, dim=1)\n",
    "label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "df[\"sentiment_score\"] = sentiment_scores.numpy()\n",
    "df[\"sentiment_label\"] = [label_map[i.item()] for i in pred_indices]\n",
    "df.to_csv(\"data/tiktok_comments_with_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea4abcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_label\n",
       "positive    2258\n",
       "neutral     1304\n",
       "negative     583\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment_label\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
